{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prologue\n",
    "\n",
    "- In this project I will perform a natural language parsing analysis to gain deeper insight into one of two famous and often discussed novels in the public domain: Oscar Wilde’s <i>Homer’s The Iliad</i>! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(\"the_illiad.txt\", encoding = 'utf-8').read().lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "sentences = sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "tokens = [word_tokenize(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P-O-S Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "\n",
    "tagged = [pos_tag(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 'DT'), ('iliad', 'NN'), ('of', 'IN'), ('homer', 'NN'), ('translated', 'VBN'), ('by', 'IN'), ('alexander', 'NN'), ('pope', 'NN'), (',', ','), ('with', 'IN'), ('notes', 'NNS'), ('by', 'IN'), ('the', 'DT'), ('rev', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "print(tagged[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NP-Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "NP_ChunkGram = \"NP: {<DT>?<JJ>*<NN>}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import RegexpParser\n",
    "\n",
    "NP_ChunkParser = RegexpParser(NP_ChunkGram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "NP_ChunkedText = [NP_ChunkParser.parse(sentence) for sentence in tagged]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VP-Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "VP_ChunkGram = \"VP: {<DT>?<JJ>*<NN><VB.*><RB.?>?}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "VP_ChunkParser = RegexpParser(VP_ChunkGram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "VP_ChunkedText = [VP_ChunkParser.parse(sentence) for sentence in tagged]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discovering Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((('hector', 'NN'),), 322),\n",
       " ((('i', 'NN'),), 274),\n",
       " ((('jove', 'NN'),), 257),\n",
       " ((('troy', 'NN'),), 208),\n",
       " ((('vain', 'NN'),), 195),\n",
       " ((('war', 'NN'),), 193),\n",
       " ((('son', 'NN'),), 170),\n",
       " ((('thou', 'NN'),), 158),\n",
       " ((('the', 'DT'), ('plain', 'NN')), 157),\n",
       " ((('the', 'DT'), ('field', 'NN')), 154),\n",
       " ((('the', 'DT'), ('ground', 'NN')), 138),\n",
       " ((('death', 'NN'),), 134),\n",
       " ((('hand', 'NN'),), 134),\n",
       " ((('greece', 'NN'),), 128),\n",
       " ((('heaven', 'NN'),), 127),\n",
       " ((('fate', 'NN'),), 127),\n",
       " ((('thee', 'NN'),), 122),\n",
       " ((('breast', 'NN'),), 121),\n",
       " ((('the', 'DT'), ('trojan', 'NN')), 120),\n",
       " ((('the', 'DT'), ('god', 'NN')), 119),\n",
       " ((('the', 'DT'), ('war', 'NN')), 117),\n",
       " ((('the', 'DT'), ('greeks', 'NN')), 116),\n",
       " ((('blood', 'NN'),), 115),\n",
       " ((('homer', 'NN'),), 112),\n",
       " ((('the', 'DT'), ('king', 'NN')), 105),\n",
       " ((('rage', 'NN'),), 103),\n",
       " ((('force', 'NN'),), 103),\n",
       " ((('care', 'NN'),), 99),\n",
       " ((('head', 'NN'),), 98),\n",
       " ((('man', 'NN'),), 97)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Chunk_Counter import np_chunk_counter, vp_chunk_counter\n",
    "\n",
    "np_chunk_counter(NP_ChunkedText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(((\"'t\", 'NN'), ('is', 'VBZ')), 19),\n",
       " ((('i', 'NN'), ('am', 'VBP')), 11),\n",
       " (((\"'t\", 'NN'), ('was', 'VBD')), 11),\n",
       " ((('the', 'DT'), ('hero', 'NN'), ('said', 'VBD')), 9),\n",
       " ((('i', 'NN'), ('know', 'VBP')), 8),\n",
       " ((('i', 'NN'), ('saw', 'VBD')), 8),\n",
       " ((('the', 'DT'), ('scene', 'NN'), ('lies', 'VBZ')), 7),\n",
       " ((('i', 'NN'), ('was', 'VBD')), 6),\n",
       " ((('confess', 'NN'), (\"'d\", 'VBD')), 6),\n",
       " ((('the', 'DT'), ('scene', 'NN'), ('is', 'VBZ')), 6),\n",
       " ((('view', 'NN'), (\"'d\", 'VBD')), 5),\n",
       " ((('i', 'NN'), ('felt', 'VBD')), 5),\n",
       " ((('i', 'NN'), ('bear', 'VBP')), 5),\n",
       " ((('hector', 'NN'), ('is', 'VBZ')), 5),\n",
       " ((('vain', 'NN'), ('was', 'VBD')), 5),\n",
       " ((('homer', 'NN'), ('was', 'VBD')), 4),\n",
       " ((('i', 'NN'), ('have', 'VBP')), 4),\n",
       " ((('hunger', 'NN'), ('was', 'VBD')), 4),\n",
       " ((('glory', 'NN'), ('lost', 'VBN')), 4),\n",
       " ((('i', 'NN'), ('see', 'VBP')), 4),\n",
       " ((('war', 'NN'), ('be', 'VB')), 4),\n",
       " ((('the', 'DT'), ('weapon', 'NN'), ('stood', 'VBD')), 4),\n",
       " ((('i', 'NN'), ('go', 'VBP')), 4),\n",
       " ((('the', 'DT'), ('silence', 'NN'), ('broke', 'VBD')), 4),\n",
       " ((('the', 'DT'), ('trojan', 'NN'), ('bands', 'VBZ')), 4),\n",
       " ((('father', 'NN'), ('gave', 'VBD')), 4),\n",
       " ((('i', 'NN'), ('deem', 'VBP')), 4),\n",
       " ((('minerva', 'NN'), ('repressing', 'VBG')), 3),\n",
       " ((('thetis', 'NN'), ('calling', 'VBG')), 3),\n",
       " ((('thetis', 'NN'), ('entreating', 'VBG')), 3)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vp_chunk_counter(VP_ChunkedText)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Looking at most common np chunks, you can identify characters of importance in the text such as hector and jove based on their frequency. \n",
    "- Additionally a location of importance, troy, is mentioned often.\n",
    "- A theme of war can also implied by its high frequency count."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Looking at most_common vp chunks, you can see that verb phrases of the form you defined in your chunk grammar do not appear as often in The Iliad as noun phrases. \n",
    "- This can indicate a different style of writing taken by the author that does not follow traditional grammatical style (i.e. poetry). \n",
    "- Even when chunks are not found, their absence can give you insight!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
